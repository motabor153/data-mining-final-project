{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f35cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q geopy tqdm\n",
    "!pip install -q pycountry_convert\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc8ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b266d8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unnamed: 0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Entity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Year",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Records",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Organization type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Method",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Sources",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "42bc70c5-c3b0-46fb-9426-aa8bdb1f80e0",
       "rows": [
        [
         "0",
         "0",
         "21st Century Oncology",
         "2016",
         "2200000",
         "healthcare",
         "hacked",
         "[5][6]"
        ],
        [
         "1",
         "1",
         "500px",
         "2020",
         "14870304",
         "social networking",
         "hacked",
         "[7]"
        ],
        [
         "2",
         "2",
         "Accendo Insurance Co.",
         "2020",
         "175350",
         "healthcare",
         "poor security",
         "[8][9]"
        ],
        [
         "3",
         "3",
         "Adobe Systems Incorporated",
         "2013",
         "152000000",
         "tech",
         "hacked",
         "[10]"
        ],
        [
         "4",
         "4",
         "Adobe Inc.",
         "2019",
         "7500000",
         "tech",
         "poor security",
         "[11][12]"
        ],
        [
         "5",
         "5",
         "Advocate Medical Group",
         "2017",
         "4000000",
         "healthcare",
         "lost / stolen media",
         "[13][14]"
        ],
        [
         "6",
         "6",
         "AerServ (subsidiary of InMobi)",
         "2018",
         "75000",
         "advertising",
         "hacked",
         "[15]"
        ],
        [
         "7",
         "7",
         "Affinity Health Plan, Inc.",
         "2013",
         "344579",
         "healthcare",
         "lost / stolen media",
         "[16][17]"
        ],
        [
         "8",
         "8",
         "Airtel",
         "2019",
         "320000000",
         "telecommunications",
         "poor security",
         "[18]"
        ],
        [
         "9",
         "9",
         "Air Canada",
         "2018",
         "20000",
         "transport",
         "hacked",
         "[19]"
        ],
        [
         "10",
         "10",
         "Amazon Japan G.K.",
         "2019",
         "unknown",
         "web",
         "accidentally published",
         "[20][21]"
        ],
        [
         "11",
         "11",
         "TD Ameritrade",
         "2005",
         "200000",
         "financial",
         "lost / stolen media",
         "[22]"
        ],
        [
         "12",
         "12",
         "Ancestry.com",
         "2021",
         "300000",
         "web",
         "poor security",
         "[23]"
        ],
        [
         "13",
         "13",
         "Animal Jam",
         "2020",
         "46000000",
         "gaming",
         "hacked",
         "[24]"
        ],
        [
         "14",
         "14",
         "Ankle & Foot Center of Tampa Bay, Inc.",
         "2021",
         "156000",
         "healthcare",
         "hacked",
         "[25]"
        ],
        [
         "15",
         "15",
         "Anthem Inc.",
         "2015",
         "80000000",
         "healthcare",
         "hacked",
         "[26][27]"
        ],
        [
         "16",
         "16",
         "AOL",
         "2004",
         "92000000",
         "web",
         "inside job, hacked",
         "[28][29]"
        ],
        [
         "17",
         "17",
         "AOL",
         "2006",
         "20000000",
         "web",
         "accidentally published",
         "[30]"
        ],
        [
         "18",
         "18",
         "AOL",
         "2014",
         "2400000",
         "web",
         "hacked",
         "[31]"
        ],
        [
         "19",
         "19",
         "Apple, Inc./BlueToad",
         "2021",
         "12367232",
         "tech, retail",
         "accidentally published",
         "[32]"
        ],
        [
         "20",
         "20",
         "Apple",
         "2021",
         "275000",
         "tech",
         "hacked",
         "[33]"
        ],
        [
         "21",
         "21",
         "Apple Health Medicaid",
         "2021",
         "91000",
         "healthcare",
         "poor security",
         "[34]"
        ],
        [
         "22",
         "22",
         "Ashley Madison",
         "2015",
         "32000000",
         "web",
         "hacked",
         "[35]"
        ],
        [
         "23",
         "23",
         "AT&T",
         "2008",
         "113000",
         "telecoms",
         "lost / stolen computer",
         "[36]"
        ],
        [
         "24",
         "24",
         "AT&T",
         "2010",
         "114000",
         "telecoms",
         "hacked",
         "[37]"
        ],
        [
         "25",
         "25",
         "Atraf",
         "2021",
         "unknown",
         "dating",
         "hacked",
         "[38]"
        ],
        [
         "26",
         "26",
         "Auction.co.kr",
         "2008",
         "18000000",
         "web",
         "hacked",
         "[39]"
        ],
        [
         "27",
         "27",
         "Australian Immigration Department",
         "2015",
         "G20 world leaders",
         "government",
         "accidentally published",
         "[40]"
        ],
        [
         "28",
         "28",
         "Australian National University",
         "2019",
         "19 years of data",
         "academic",
         "hacked",
         "[41]"
        ],
        [
         "29",
         "29",
         "Automatic Data Processing",
         "2005",
         "125000",
         "financial",
         "poor security",
         "[42]"
        ],
        [
         "30",
         "30",
         "AvMed, Inc.",
         "2009",
         "1220000",
         "healthcare",
         "lost / stolen computer",
         "[43]"
        ],
        [
         "31",
         "31",
         "Bailey's Inc.",
         "2015",
         "250000",
         "retail",
         "hacked",
         "[44]"
        ],
        [
         "32",
         "32",
         "The Bank of New York Mellon",
         "2008",
         "12500000",
         "financial",
         "lost / stolen media",
         "[45]"
        ],
        [
         "33",
         "33",
         "Bank of America",
         "2005",
         "1200000",
         "financial",
         "lost / stolen media",
         "[46]"
        ],
        [
         "34",
         "34",
         "Barnes & Noble",
         "2012",
         "63 stores",
         "retail",
         "hacked",
         "[47][48]"
        ],
        [
         "35",
         "35",
         "Bell Canada",
         "2017",
         "1900000",
         "telecoms",
         "poor security",
         "[49]"
        ],
        [
         "36",
         "36",
         "Bell Canada",
         "2018",
         "100000",
         "telecoms",
         "hacked",
         "[50]"
        ],
        [
         "37",
         "37",
         "Benesse",
         "2014",
         "35040000",
         "educational services",
         "hacked",
         "[51]"
        ],
        [
         "38",
         "38",
         "Betfair",
         "2010",
         "2300000",
         "web",
         "hacked",
         "[36]"
        ],
        [
         "39",
         "39",
         "Bethesda Game Studios",
         "2011",
         "200000",
         "gaming",
         "hacked",
         "[52]"
        ],
        [
         "40",
         "40",
         "Bethesda Game Studios",
         "2018",
         null,
         "gaming",
         "accidentally published",
         "[53]"
        ],
        [
         "41",
         "41",
         "Betsson Group",
         "2020",
         "unknown",
         "gambling",
         "unknown",
         "[54]"
        ],
        [
         "42",
         "42",
         "Blank Media Games",
         "2018",
         "7633234",
         "gaming",
         "hacked",
         "[55][56]"
        ],
        [
         "43",
         "43",
         "Blizzard Entertainment",
         "2012",
         "14000000",
         "gaming",
         "hacked",
         "[57][58]"
        ],
        [
         "44",
         "44",
         "BlueCross BlueShield of Tennessee",
         "2009",
         "1023209",
         "healthcare",
         "lost / stolen media",
         "[59]"
        ],
        [
         "45",
         "45",
         "BMO and Simplii",
         "2018",
         "90000",
         "banking",
         "poor security",
         "[60]"
        ],
        [
         "46",
         "46",
         "2018 British Airways cyberattack",
         "2018",
         "500000",
         "transport",
         "hacked",
         "[61][62][63]"
        ],
        [
         "47",
         "47",
         "British Airways",
         "2015",
         "tens of thousands",
         "retail",
         "hacked",
         "[64]"
        ],
        [
         "48",
         "48",
         "2019 Bulgarian revenue agency hack",
         "2019",
         "over 5,000,000",
         "government",
         "hacked",
         "[65]"
        ],
        [
         "49",
         "49",
         "California Department of Child Support Services",
         "2012",
         "800000",
         "government",
         "lost / stolen media",
         "[36][66]"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 352
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Year</th>\n",
       "      <th>Records</th>\n",
       "      <th>Organization type</th>\n",
       "      <th>Method</th>\n",
       "      <th>Sources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21st Century Oncology</td>\n",
       "      <td>2016</td>\n",
       "      <td>2200000</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>hacked</td>\n",
       "      <td>[5][6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>500px</td>\n",
       "      <td>2020</td>\n",
       "      <td>14870304</td>\n",
       "      <td>social networking</td>\n",
       "      <td>hacked</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Accendo Insurance Co.</td>\n",
       "      <td>2020</td>\n",
       "      <td>175350</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>poor security</td>\n",
       "      <td>[8][9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Adobe Systems Incorporated</td>\n",
       "      <td>2013</td>\n",
       "      <td>152000000</td>\n",
       "      <td>tech</td>\n",
       "      <td>hacked</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Adobe Inc.</td>\n",
       "      <td>2019</td>\n",
       "      <td>7500000</td>\n",
       "      <td>tech</td>\n",
       "      <td>poor security</td>\n",
       "      <td>[11][12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>347</td>\n",
       "      <td>Zynga</td>\n",
       "      <td>2019</td>\n",
       "      <td>173000000</td>\n",
       "      <td>social network</td>\n",
       "      <td>hacked</td>\n",
       "      <td>[406][407]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>348</td>\n",
       "      <td>Unknown agency(believed to be tied to United S...</td>\n",
       "      <td>2020</td>\n",
       "      <td>200000000</td>\n",
       "      <td>financial</td>\n",
       "      <td>accidentally published</td>\n",
       "      <td>[408]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>349</td>\n",
       "      <td>National Health Information Center (NCZI) of S...</td>\n",
       "      <td>2020</td>\n",
       "      <td>391250</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>poor security</td>\n",
       "      <td>[409]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>350</td>\n",
       "      <td>50 companies and government institutions</td>\n",
       "      <td>2022</td>\n",
       "      <td>6400000</td>\n",
       "      <td>various</td>\n",
       "      <td>poor security</td>\n",
       "      <td>[410] [411]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>351</td>\n",
       "      <td>IKEA</td>\n",
       "      <td>2022</td>\n",
       "      <td>95000</td>\n",
       "      <td>retail</td>\n",
       "      <td>accidentally published</td>\n",
       "      <td>[412]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                             Entity  Year  \\\n",
       "0             0                              21st Century Oncology  2016   \n",
       "1             1                                              500px  2020   \n",
       "2             2                              Accendo Insurance Co.  2020   \n",
       "3             3                         Adobe Systems Incorporated  2013   \n",
       "4             4                                         Adobe Inc.  2019   \n",
       "..          ...                                                ...   ...   \n",
       "347         347                                              Zynga  2019   \n",
       "348         348  Unknown agency(believed to be tied to United S...  2020   \n",
       "349         349  National Health Information Center (NCZI) of S...  2020   \n",
       "350         350           50 companies and government institutions  2022   \n",
       "351         351                                               IKEA  2022   \n",
       "\n",
       "       Records  Organization type                  Method      Sources  \n",
       "0      2200000         healthcare                  hacked       [5][6]  \n",
       "1     14870304  social networking                  hacked          [7]  \n",
       "2       175350         healthcare           poor security       [8][9]  \n",
       "3    152000000               tech                  hacked         [10]  \n",
       "4      7500000               tech           poor security     [11][12]  \n",
       "..         ...                ...                     ...          ...  \n",
       "347  173000000     social network                  hacked   [406][407]  \n",
       "348  200000000          financial  accidentally published        [408]  \n",
       "349     391250         healthcare           poor security        [409]  \n",
       "350    6400000            various           poor security  [410] [411]  \n",
       "351      95000             retail  accidentally published        [412]  \n",
       "\n",
       "[352 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('df_1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5fb438",
   "metadata": {},
   "source": [
    "# Create a Country feature from the Entity feature\n",
    "- Will use the Nominatim free api in a function that takes an organization/company name and returns the country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d29e5483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import time\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"data_breach_locator\")\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)  # API polite usage\n",
    "\n",
    "def entity_to_country(entity):\n",
    "    try:\n",
    "        # Add “company headquarters” to improve accuracy\n",
    "        query = f\"{entity} headquarters\"\n",
    "        location = geocode(query)\n",
    "\n",
    "        if location is None:\n",
    "            # fallback: try entity name only\n",
    "            location = geocode(entity)\n",
    "\n",
    "        if location:\n",
    "            # country is usually the last part of the address\n",
    "            return location.address.split(\",\")[-1].strip()\n",
    "\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86a1f583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10/331 [00:20<08:15,  1.54s/it]RateLimiter caught an error, retrying (0/2 tries). Called with (*('Amazon Japan G.K. headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Amazon+Japan+G.K.+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Amazon+Japan+G.K.+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Amazon+Japan+G.K.+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('Amazon Japan G.K. headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Amazon+Japan+G.K.+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Amazon+Japan+G.K.+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Amazon+Japan+G.K.+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('Amazon Japan G.K. headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Amazon+Japan+G.K.+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Amazon+Japan+G.K.+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Amazon+Japan+G.K.+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('Amazon Japan G.K.',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Amazon+Japan+G.K.&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Amazon+Japan+G.K.&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Amazon+Japan+G.K.&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "  9%|▉         | 30/331 [01:29<10:24,  2.08s/it]RateLimiter caught an error, retrying (0/2 tries). Called with (*('Bank of America headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Bank+of+America+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Bank+of+America+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Bank+of+America+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('Bank of America headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Bank+of+America+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Bank+of+America+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Bank+of+America+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      " 14%|█▍        | 47/331 [02:32<09:43,  2.05s/it]RateLimiter caught an error, retrying (0/2 tries). Called with (*('Capital One headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Capital+One+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Capital+One+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Capital+One+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      " 19%|█▊        | 62/331 [03:17<12:32,  2.80s/it]RateLimiter caught an error, retrying (0/2 tries). Called with (*('Philippines Commission on Elections headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Philippines+Commission+on+Elections+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Philippines+Commission+on+Elections+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Philippines+Commission+on+Elections+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('Philippines Commission on Elections headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Philippines+Commission+on+Elections+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Philippines+Commission+on+Elections+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Philippines+Commission+on+Elections+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('Philippines Commission on Elections headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Philippines+Commission+on+Elections+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Philippines+Commission+on+Elections+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Philippines+Commission+on+Elections+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      " 23%|██▎       | 76/331 [04:06<09:24,  2.21s/it]RateLimiter caught an error, retrying (0/2 tries). Called with (*('US Department of Homeland Security headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=US+Department+of+Homeland+Security+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=US+Department+of+Homeland+Security+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=US+Department+of+Homeland+Security+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      " 29%|██▉       | 96/331 [05:04<09:01,  2.30s/it]RateLimiter caught an error, retrying (0/2 tries). Called with (*('European Central Bank headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=European+Central+Bank+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=European+Central+Bank+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=European+Central+Bank+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('European Central Bank headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=European+Central+Bank+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=European+Central+Bank+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=European+Central+Bank+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('European Central Bank headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=European+Central+Bank+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=European+Central+Bank+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=European+Central+Bank+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      " 40%|████      | 134/331 [06:56<09:11,  2.80s/it]RateLimiter caught an error, retrying (0/2 tries). Called with (*('Honda Canada headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Honda+Canada+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Honda+Canada+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Honda+Canada+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      " 44%|████▎     | 144/331 [07:23<07:10,  2.30s/it]RateLimiter caught an error, retrying (0/2 tries). Called with (*('Jefferson County, West Virginia headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Jefferson+County%2C+West+Virginia+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Jefferson+County%2C+West+Virginia+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Jefferson+County%2C+West+Virginia+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      " 51%|█████     | 168/331 [08:26<06:49,  2.51s/it]RateLimiter caught an error, retrying (0/2 tries). Called with (*('Memorial Healthcare System headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Memorial+Healthcare+System+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Memorial+Healthcare+System+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Memorial+Healthcare+System+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      " 53%|█████▎    | 177/331 [08:55<07:00,  2.73s/it]RateLimiter caught an error, retrying (0/2 tries). Called with (*('Mobile TeleSystems (MTS)',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Mobile+TeleSystems+%28MTS%29&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Mobile+TeleSystems+%28MTS%29&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Mobile+TeleSystems+%28MTS%29&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      " 64%|██████▎   | 211/331 [10:14<04:07,  2.06s/it]RateLimiter caught an error, retrying (0/2 tries). Called with (*('Puerto Rico Department of Health',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Puerto+Rico+Department+of+Health&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Puerto+Rico+Department+of+Health&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Puerto+Rico+Department+of+Health&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('Puerto Rico Department of Health',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Puerto+Rico+Department+of+Health&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Puerto+Rico+Department+of+Health&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Puerto+Rico+Department+of+Health&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('Puerto Rico Department of Health',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Puerto+Rico+Department+of+Health&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Puerto+Rico+Department+of+Health&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Puerto+Rico+Department+of+Health&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      " 66%|██████▋   | 220/331 [10:58<04:46,  2.58s/it]RateLimiter caught an error, retrying (0/2 tries). Called with (*('Rosen Hotels',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Rosen+Hotels&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Rosen+Hotels&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Rosen+Hotels&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('Rosen Hotels',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Rosen+Hotels&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Rosen+Hotels&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Rosen+Hotels&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('Rosen Hotels',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Rosen+Hotels&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Rosen+Hotels&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Rosen+Hotels&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      " 74%|███████▍  | 245/331 [12:15<03:46,  2.63s/it]RateLimiter caught an error, retrying (0/2 tries). Called with (*('State of Texas headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 196, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 85, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "OSError: [WinError 10051] A socket operation was attempted to an unreachable network\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 490, in _make_request\n",
      "    raise new_e\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 466, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1095, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 615, in connect\n",
      "    self.sock = sock = self._new_conn()\n",
      "                       ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 211, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x0000026E2F000290>: Failed to establish a new connection: [WinError 10051] A socket operation was attempted to an unreachable network\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=State+of+Texas+headquarters&format=json&limit=1 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000026E2F000290>: Failed to establish a new connection: [WinError 10051] A socket operation was attempted to an unreachable network'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=State+of+Texas+headquarters&format=json&limit=1 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000026E2F000290>: Failed to establish a new connection: [WinError 10051] A socket operation was attempted to an unreachable network'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=State+of+Texas+headquarters&format=json&limit=1 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000026E2F000290>: Failed to establish a new connection: [WinError 10051] A socket operation was attempted to an unreachable network'))\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('State of Texas headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 196, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 60, in create_connection\n",
      "    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 964, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "socket.gaierror: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 490, in _make_request\n",
      "    raise new_e\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 466, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1095, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 615, in connect\n",
      "    self.sock = sock = self._new_conn()\n",
      "                       ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 203, in _new_conn\n",
      "    raise NameResolutionError(self.host, self, e) from e\n",
      "urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x0000026E2E8E1FA0>: Failed to resolve 'nominatim.openstreetmap.org' ([Errno 11001] getaddrinfo failed)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=State+of+Texas+headquarters&format=json&limit=1 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000026E2E8E1FA0>: Failed to resolve 'nominatim.openstreetmap.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=State+of+Texas+headquarters&format=json&limit=1 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000026E2E8E1FA0>: Failed to resolve 'nominatim.openstreetmap.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=State+of+Texas+headquarters&format=json&limit=1 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000026E2E8E1FA0>: Failed to resolve 'nominatim.openstreetmap.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('State of Texas headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 196, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 60, in create_connection\n",
      "    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 964, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "socket.gaierror: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 490, in _make_request\n",
      "    raise new_e\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 466, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1095, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 615, in connect\n",
      "    self.sock = sock = self._new_conn()\n",
      "                       ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 203, in _new_conn\n",
      "    raise NameResolutionError(self.host, self, e) from e\n",
      "urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x0000026E2F007DA0>: Failed to resolve 'nominatim.openstreetmap.org' ([Errno 11001] getaddrinfo failed)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=State+of+Texas+headquarters&format=json&limit=1 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000026E2F007DA0>: Failed to resolve 'nominatim.openstreetmap.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=State+of+Texas+headquarters&format=json&limit=1 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000026E2F007DA0>: Failed to resolve 'nominatim.openstreetmap.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=State+of+Texas+headquarters&format=json&limit=1 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000026E2F007DA0>: Failed to resolve 'nominatim.openstreetmap.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('State of Texas',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 196, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 60, in create_connection\n",
      "    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 964, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "socket.gaierror: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 490, in _make_request\n",
      "    raise new_e\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 466, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1095, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 615, in connect\n",
      "    self.sock = sock = self._new_conn()\n",
      "                       ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 203, in _new_conn\n",
      "    raise NameResolutionError(self.host, self, e) from e\n",
      "urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x0000026E2F006FF0>: Failed to resolve 'nominatim.openstreetmap.org' ([Errno 11001] getaddrinfo failed)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=State+of+Texas&format=json&limit=1 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000026E2F006FF0>: Failed to resolve 'nominatim.openstreetmap.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=State+of+Texas&format=json&limit=1 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000026E2F006FF0>: Failed to resolve 'nominatim.openstreetmap.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=State+of+Texas&format=json&limit=1 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000026E2F006FF0>: Failed to resolve 'nominatim.openstreetmap.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      " 86%|████████▋ | 286/331 [22:41<01:46,  2.37s/it]   RateLimiter caught an error, retrying (0/2 tries). Called with (*('University of Miami headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=University+of+Miami+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=University+of+Miami+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=University+of+Miami+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      " 87%|████████▋ | 287/331 [22:52<03:28,  4.75s/it]RateLimiter caught an error, retrying (0/2 tries). Called with (*('University of Utah Hospital & Clinics headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=University+of+Utah+Hospital+%26+Clinics+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=University+of+Utah+Hospital+%26+Clinics+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=University+of+Utah+Hospital+%26+Clinics+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('University of Utah Hospital & Clinics headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=University+of+Utah+Hospital+%26+Clinics+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=University+of+Utah+Hospital+%26+Clinics+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=University+of+Utah+Hospital+%26+Clinics+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('University of Utah Hospital & Clinics headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=University+of+Utah+Hospital+%26+Clinics+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=University+of+Utah+Hospital+%26+Clinics+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=University+of+Utah+Hospital+%26+Clinics+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('University of Utah Hospital & Clinics',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=University+of+Utah+Hospital+%26+Clinics&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=University+of+Utah+Hospital+%26+Clinics&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=University+of+Utah+Hospital+%26+Clinics&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      " 87%|████████▋ | 289/331 [23:25<06:36,  9.44s/it]RateLimiter caught an error, retrying (0/2 tries). Called with (*('United States Postal Service headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=United+States+Postal+Service+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=United+States+Postal+Service+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=United+States+Postal+Service+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      " 89%|████████▊ | 293/331 [23:43<03:35,  5.67s/it]RateLimiter caught an error, retrying (0/2 tries). Called with (*('U.S. Department of Defense headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=U.S.+Department+of+Defense+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=U.S.+Department+of+Defense+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=U.S.+Department+of+Defense+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      " 99%|█████████▉| 327/331 [25:09<00:07,  1.89s/it]RateLimiter caught an error, retrying (0/2 tries). Called with (*('Unknown agency(believed to be tied to United States Census Bureau) headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Unknown+agency%28believed+to+be+tied+to+United+States+Census+Bureau%29+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Unknown+agency%28believed+to+be+tied+to+United+States+Census+Bureau%29+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Unknown+agency%28believed+to+be+tied+to+United+States+Census+Bureau%29+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('Unknown agency(believed to be tied to United States Census Bureau) headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Unknown+agency%28believed+to+be+tied+to+United+States+Census+Bureau%29+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Unknown+agency%28believed+to+be+tied+to+United+States+Census+Bureau%29+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Unknown+agency%28believed+to+be+tied+to+United+States+Census+Bureau%29+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('Unknown agency(believed to be tied to United States Census Bureau) headquarters',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\http\\client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 589, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 873, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Unknown+agency%28believed+to+be+tied+to+United+States+Census+Bureau%29+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 622, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Unknown+agency%28believed+to+be+tied+to+United+States+Census+Bureau%29+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mat\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Unknown+agency%28believed+to+be+tied+to+United+States+Census+Bureau%29+headquarters&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "100%|██████████| 331/331 [25:40<00:00,  4.65s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "entities = df['Entity'].unique().tolist()\n",
    "\n",
    "entity_country_map = {}\n",
    "\n",
    "for e in tqdm(entities):\n",
    "    country = entity_to_country(e)\n",
    "    entity_country_map[e] = country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e406310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Entity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "899969f7-6021-4c72-bbea-3fc19379a0ad",
       "rows": [
        [
         "0",
         "21st Century Oncology",
         "United States of America"
        ],
        [
         "1",
         "500px",
         null
        ],
        [
         "2",
         "Accendo Insurance Co.",
         null
        ],
        [
         "3",
         "Adobe Systems Incorporated",
         null
        ],
        [
         "4",
         "Adobe Inc.",
         "United States of America"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21st Century Oncology</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500px</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accendo Insurance Co.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adobe Systems Incorporated</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adobe Inc.</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Entity                   Country\n",
       "0       21st Century Oncology  United States of America\n",
       "1                       500px                      None\n",
       "2       Accendo Insurance Co.                      None\n",
       "3  Adobe Systems Incorporated                      None\n",
       "4                  Adobe Inc.  United States of America"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_df = pd.DataFrame(list(entity_country_map.items()), \n",
    "                      columns=['Entity', 'Country'])\n",
    "loc_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8e3fbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(loc_df, on=\"Entity\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a20a21b",
   "metadata": {},
   "source": [
    "# Add Continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e76ba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry_convert as pc\n",
    "\n",
    "def country_to_continent(country):\n",
    "    try:\n",
    "        code = pc.country_name_to_country_alpha2(country)\n",
    "        cont_code = pc.country_alpha2_to_continent_code(code)\n",
    "        return pc.convert_continent_code_to_continent_name(cont_code)\n",
    "    except:\n",
    "        return \"Unknown\"\n",
    "\n",
    "df['Continent'] = df['Country'].apply(\n",
    "    lambda x: country_to_continent(x) if pd.notnull(x) else \"Unknown\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4489b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['500px', 'Accendo Insurance Co.', 'Adobe Systems Incorporated',\n",
       "       'AerServ (subsidiary of InMobi)', 'Affinity Health Plan, Inc.',\n",
       "       'Amazon Japan G.K.', 'Ancestry.com', 'Animal Jam',\n",
       "       'Ankle & Foot Center of Tampa Bay, Inc.', 'Apple, Inc./BlueToad',\n",
       "       'Apple Health Medicaid', 'Atraf', 'Auction.co.kr',\n",
       "       'Australian Immigration Department', 'Automatic Data Processing',\n",
       "       'AvMed, Inc.', 'Benesse', 'Betfair', 'Betsson Group',\n",
       "       'Blank Media Games', 'Blizzard Entertainment', 'BMO and Simplii',\n",
       "       '2018 British Airways cyberattack',\n",
       "       '2019 Bulgarian revenue agency hack',\n",
       "       'California Department of Child Support Services', 'Canva',\n",
       "       'CardSystems Solutions Inc. (MasterCard, Visa, Discover Financial Services and American Express)',\n",
       "       'Cathay Pacific Airways',\n",
       "       'CareFirst BlueCross Blue Shield - Maryland',\n",
       "       'CheckFree Corporation', 'CheckPeople',\n",
       "       'China Software Developer Network',\n",
       "       'Chinese gaming websites (three: Duowan, 7K7K, 178.com)',\n",
       "       'City and Hackney Teaching Primary Care Trust',\n",
       "       'Countrywide Financial Corp', 'Crescent Health Inc., Walgreens',\n",
       "       'CyberServe', 'Dai Nippon Printing',\n",
       "       'Data Processors International (MasterCard, Visa, Discover Financial Services and American Express)',\n",
       "       'Defense Integrated Data Center (South Korea)', 'Dedalus',\n",
       "       'DSW Inc.', 'Dubsmash', 'eBay',\n",
       "       'Earl Enterprises(Buca di Beppo, Earl of Sandwich, Planet Hollywood,Chicken Guy, Mixology, Tequila Taqueria)',\n",
       "       'Educational Credit Management Corporation', 'ElasticSearch',\n",
       "       'Embassy Cables', 'Emergency Healthcare Physicians, Ltd.',\n",
       "       'European Central Bank', 'Evernote', 'Exactis',\n",
       "       'Experian - T-Mobile US', 'EyeWire', 'Fast Retailing',\n",
       "       'Friend Finder Networks', 'Funimation', 'Formspring', 'Gamigo',\n",
       "       'Google Plus', 'Grozio Chirurgija', 'GS Caltex',\n",
       "       'Hannaford Brothers Supermarket Chain', 'HauteLook',\n",
       "       'Health Net\\xa0— IBM', 'Health Service Executive', 'Hilton Hotels',\n",
       "       'Iberdrola', 'International Committee of the Red Cross',\n",
       "       'Iranian banks (three: Saderat, Eghtesad Novin, and Saman)',\n",
       "       'Japan Pension Service', 'Japanet Takata', 'KDDI', 'Koodo Mobile',\n",
       "       'Korea Credit Bureau', 'Kroll Background America',\n",
       "       'KT Corporation', \"Landry's, Inc.\", 'Les Éditions Protégez-vous',\n",
       "       'Lincoln Medical & Mental Health Center',\n",
       "       'LinkedIn, eHarmony, Last.fm', 'MacRumors.com',\n",
       "       'Massive American business hack including 7-Eleven and Nasdaq',\n",
       "       'Medical Informatics Engineering', 'Microsoft Exchange servers',\n",
       "       'Militarysingles.com', 'Ministry of Education (Chile)',\n",
       "       'Mitsubishi Tokyo UFJ Bank', 'Mobile TeleSystems (MTS)',\n",
       "       'Monster.com', 'Morinaga Confectionery', 'MyHeritage',\n",
       "       'NEC Networks, LLC', 'Nemours Foundation', 'Network Solutions',\n",
       "       'New York City Health & Hospitals Corp.', 'Nexon Korea Corp',\n",
       "       'Nintendo (Club Nintendo)', 'Nintendo (Nintendo Account)',\n",
       "       'Nippon Television', 'Nival Networks',\n",
       "       'Norwegian Tax Administration',\n",
       "       'Office of the Texas Attorney General', 'Orbitz', 'Patreon',\n",
       "       'Popsugar', 'Premera', 'Puerto Rico Department of Health',\n",
       "       'Rakuten', 'Reddit', 'Restaurant Depot', 'RockYou!',\n",
       "       'Rosen Hotels', 'Sakai City, Japan', 'Scribd',\n",
       "       'Seacoast Radiology, PA',\n",
       "       'Service Personnel and Veterans Agency (UK)', 'SlickWraps',\n",
       "       'SolarWinds', 'Sony Online Entertainment',\n",
       "       'Sony PlayStation Network',\n",
       "       'Southern California Medical-Legal Consultants',\n",
       "       'Spartanburg Regional Healthcare System',\n",
       "       'Starwoodincluding Westin Hotels & Resorts and Sheraton Hotels and Resorts',\n",
       "       'Stratfor', 'Supervalu', 'Syrian government (Syria Files)',\n",
       "       'Taobao', 'TaxSlayer.com', 'TerraCom & YourTel', 'Tetrad',\n",
       "       'Ticketfly (subsidiary of Eventbrite)', 'Tianya Club', 'TikTok',\n",
       "       'T-Mobile, Deutsche Telekom', 'Triple-S Salud, Inc.', 'Typeform',\n",
       "       'Ubuntu', 'University of Utah Hospital & Clinics', 'UPS',\n",
       "       'U.S. Army(classified Iraq War documents)',\n",
       "       'U.S. federal government (2020 United States federal government data breach)',\n",
       "       'U.S. law enforcement (70 different agencies)',\n",
       "       'National Archives and Records Administration (U.S. military veterans records)',\n",
       "       'U.S. government (United States diplomatic cables leak)',\n",
       "       'Vastaamo', 'Virginia Prescription Monitoring Program', 'Vodafone',\n",
       "       'Washington State court system', 'Wattpad', 'WordPress',\n",
       "       'Writerspace.com', 'Xat.com', 'Yahoo Japan', 'Yahoo! Voices',\n",
       "       'Unknown agency(believed to be tied to United States Census Bureau)',\n",
       "       'National Health Information Center (NCZI) of Slovakia',\n",
       "       '50 companies and government institutions', 'IKEA'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknowns = df[df['Country'].isna() | (df['Continent'] == 'Unknown')]['Entity'].unique()\n",
    "unknowns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a3cbde",
   "metadata": {},
   "source": [
    "## Batch A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0d47f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Entity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Continent",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "78591fc5-48c9-4091-b98f-fd58af4d8d21",
       "rows": [
        [
         "0",
         "21st Century Oncology",
         "United States",
         "North America"
        ],
        [
         "1",
         "500px",
         "Canada",
         "North America"
        ],
        [
         "2",
         "Accendo Insurance Co.",
         "United States",
         "North America"
        ],
        [
         "3",
         "Adobe Systems Incorporated",
         "United States",
         "North America"
        ],
        [
         "4",
         "Adobe Inc.",
         "United States",
         "North America"
        ],
        [
         "5",
         "Advocate Medical Group",
         "United States",
         "North America"
        ],
        [
         "6",
         "AerServ (subsidiary of InMobi)",
         "United States",
         "North America"
        ],
        [
         "7",
         "Affinity Health Plan, Inc.",
         "United States",
         "North America"
        ],
        [
         "8",
         "Airtel",
         "India",
         "Asia"
        ],
        [
         "9",
         "Air Canada",
         "Canada",
         "North America"
        ],
        [
         "10",
         "Amazon Japan G.K.",
         "Japan",
         "Asia"
        ],
        [
         "11",
         "TD Ameritrade",
         "United States",
         "North America"
        ],
        [
         "12",
         "Ancestry.com",
         "United States",
         "North America"
        ],
        [
         "13",
         "Animal Jam",
         "United States",
         "North America"
        ],
        [
         "14",
         "Ankle & Foot Center of Tampa Bay, Inc.",
         "United States",
         "North America"
        ],
        [
         "15",
         "Anthem Inc.",
         "United States",
         "North America"
        ],
        [
         "16",
         "AOL",
         "United States",
         "North America"
        ],
        [
         "17",
         "AOL",
         "United States",
         "North America"
        ],
        [
         "18",
         "AOL",
         "United States",
         "North America"
        ],
        [
         "19",
         "Apple, Inc./BlueToad",
         "United States",
         "North America"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21st Century Oncology</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500px</td>\n",
       "      <td>Canada</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accendo Insurance Co.</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adobe Systems Incorporated</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adobe Inc.</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Advocate Medical Group</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AerServ (subsidiary of InMobi)</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Affinity Health Plan, Inc.</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Airtel</td>\n",
       "      <td>India</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Air Canada</td>\n",
       "      <td>Canada</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Amazon Japan G.K.</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TD Ameritrade</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ancestry.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal Jam</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ankle &amp; Foot Center of Tampa Bay, Inc.</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Anthem Inc.</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AOL</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AOL</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AOL</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Apple, Inc./BlueToad</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Entity        Country      Continent\n",
       "0                    21st Century Oncology  United States  North America\n",
       "1                                    500px         Canada  North America\n",
       "2                    Accendo Insurance Co.  United States  North America\n",
       "3               Adobe Systems Incorporated  United States  North America\n",
       "4                               Adobe Inc.  United States  North America\n",
       "5                   Advocate Medical Group  United States  North America\n",
       "6           AerServ (subsidiary of InMobi)  United States  North America\n",
       "7               Affinity Health Plan, Inc.  United States  North America\n",
       "8                                   Airtel          India           Asia\n",
       "9                               Air Canada         Canada  North America\n",
       "10                       Amazon Japan G.K.          Japan           Asia\n",
       "11                           TD Ameritrade  United States  North America\n",
       "12                            Ancestry.com  United States  North America\n",
       "13                              Animal Jam  United States  North America\n",
       "14  Ankle & Foot Center of Tampa Bay, Inc.  United States  North America\n",
       "15                             Anthem Inc.  United States  North America\n",
       "16                                     AOL  United States  North America\n",
       "17                                     AOL  United States  North America\n",
       "18                                     AOL  United States  North America\n",
       "19                    Apple, Inc./BlueToad  United States  North America"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this ONCE at the top of your mapping section\n",
    "df['Country'] = None\n",
    "df['Continent'] = None\n",
    "\n",
    "batch_a_mapping = {\n",
    "    \"21st Century Oncology\": (\"United States\", \"North America\"),\n",
    "    \"500px\": (\"Canada\", \"North America\"),\n",
    "    \"Accendo Insurance Co.\": (\"United States\", \"North America\"),\n",
    "    \"Adobe Systems Incorporated\": (\"United States\", \"North America\"),\n",
    "    \"Adobe Inc.\": (\"United States\", \"North America\"),\n",
    "    \"Advocate Medical Group\": (\"United States\", \"North America\"),\n",
    "    \"AerServ (subsidiary of InMobi)\": (\"United States\", \"North America\"),\n",
    "    \"Affinity Health Plan, Inc.\": (\"United States\", \"North America\"),\n",
    "    \"Airtel\": (\"India\", \"Asia\"),\n",
    "    \"Air Canada\": (\"Canada\", \"North America\"),\n",
    "    \"Amazon Japan G.K.\": (\"Japan\", \"Asia\"),\n",
    "    \"TD Ameritrade\": (\"United States\", \"North America\"),\n",
    "    \"Ancestry.com\": (\"United States\", \"North America\"),\n",
    "    \"Animal Jam\": (\"United States\", \"North America\"),\n",
    "    \"Ankle & Foot Center of Tampa Bay, Inc.\": (\"United States\", \"North America\"),\n",
    "    \"Anthem Inc.\": (\"United States\", \"North America\"),\n",
    "    \"AOL\": (\"United States\", \"North America\"),\n",
    "    \"Apple, Inc./BlueToad\": (\"United States\", \"North America\"),\n",
    "    \"Apple\": (\"United States\", \"North America\"),\n",
    "    \"Apple Health Medicaid\": (\"United States\", \"North America\"),\n",
    "    \"Ashley Madison\": (\"Canada\", \"North America\"),\n",
    "    \"AT&T\": (\"United States\", \"North America\"),\n",
    "    \"Atraf\": (\"Israel\", \"Asia\"),\n",
    "    \"Auction.co.kr\": (\"South Korea\", \"Asia\"),\n",
    "    \"Australian Immigration Department\": (\"Australia\", \"Oceania\"),\n",
    "    \"Australian National University\": (\"Australia\", \"Oceania\"),\n",
    "    \"Automatic Data Processing\": (\"United States\", \"North America\"),\n",
    "    \"AvMed, Inc.\": (\"United States\", \"North America\"),\n",
    "    \"Bailey's Inc.\": (\"United States\", \"North America\"),\n",
    "    \"The Bank of New York Mellon\": (\"United States\", \"North America\"),\n",
    "    \"Bank of America\": (\"United States\", \"North America\"),\n",
    "    \"Barnes & Noble\": (\"United States\", \"North America\"),\n",
    "    \"Bell Canada\": (\"Canada\", \"North America\"),\n",
    "    \"Benesse\": (\"Japan\", \"Asia\"),\n",
    "    \"Betfair\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"Bethesda Game Studios\": (\"United States\", \"North America\"),\n",
    "    \"Betsson Group\": (\"Malta\", \"Europe\"),\n",
    "    \"Blank Media Games\": (\"United States\", \"North America\"),\n",
    "    \"Blizzard Entertainment\": (\"United States\", \"North America\"),\n",
    "    \"BlueCross BlueShield of Tennessee\": (\"United States\", \"North America\"),\n",
    "    \"BMO and Simplii\": (\"Canada\", \"North America\"),\n",
    "    \"2018 British Airways cyberattack\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"British Airways\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"2019 Bulgarian revenue agency hack\": (\"Bulgaria\", \"Europe\"),\n",
    "    \"California Department of Child Support Services\": (\"United States\", \"North America\"),\n",
    "    \"Canva\": (\"Australia\", \"Oceania\"),\n",
    "    \"Capcom\": (\"Japan\", \"Asia\"),\n",
    "    \"Capital One\": (\"United States\", \"North America\"),\n",
    "    \"CardSystems Solutions Inc. (MasterCard, Visa, Discover Financial Services and American Express)\": (\"United States\", \"North America\"),\n",
    "    \"Cathay Pacific Airways\": (\"Hong Kong\", \"Asia\"),\n",
    "    \"CareFirst BlueCross Blue Shield - Maryland\": (\"United States\", \"North America\"),\n",
    "    \"Central Coast Credit Union\": (\"Australia\", \"Oceania\"),\n",
    "    \"Central Hudson Gas & Electric\": (\"United States\", \"North America\"),\n",
    "    \"CheckFree Corporation\": (\"United States\", \"North America\"),\n",
    "    \"CheckPeople\": (\"United States\", \"North America\"),\n",
    "    \"China Software Developer Network\": (\"China\", \"Asia\"),\n",
    "    \"Chinese gaming websites (three: Duowan, 7K7K, 178.com)\": (\"China\", \"Asia\"),\n",
    "    \"Citigroup\": (\"United States\", \"North America\"),\n",
    "    \"City and Hackney Teaching Primary Care Trust\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"Clearview AI\": (\"United States\", \"North America\"),\n",
    "    \"Colorado government\": (\"United States\", \"North America\"),\n",
    "    \"Community Health Systems\": (\"United States\", \"North America\"),\n",
    "    \"Compass Bank\": (\"United States\", \"North America\"),\n",
    "    \"Countrywide Financial Corp\": (\"United States\", \"North America\"),\n",
    "    \"Centers for Medicare & Medicaid Services\": (\"United States\", \"North America\"),\n",
    "    \"Cox Communications\": (\"United States\", \"North America\"),\n",
    "    \"Crescent Health Inc., Walgreens\": (\"United States\", \"North America\"),\n",
    "    \"CVS\": (\"United States\", \"North America\"),\n",
    "    \"CyberServe\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"Dai Nippon Printing\": (\"Japan\", \"Asia\"),\n",
    "    \"Data Processors International (MasterCard, Visa, Discover Financial Services and American Express)\": (\"United States\", \"North America\"),\n",
    "    \"Defense Integrated Data Center (South Korea)\": (\"South Korea\", \"Asia\"),\n",
    "    \"Dedalus\": (\"Italy\", \"Europe\"),\n",
    "    \"Deloitte\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"US Department of Homeland Security\": (\"United States\", \"North America\"),\n",
    "    \"Desjardins\": (\"Canada\", \"North America\"),\n",
    "    \"Domino's Pizza (France)\": (\"France\", \"Europe\"),\n",
    "    \"DoorDash\": (\"United States\", \"North America\"),\n",
    "    \"UK Driving Standards Agency\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"Dropbox\": (\"United States\", \"North America\"),\n",
    "}\n",
    "\n",
    "for entity, (country, continent) in batch_a_mapping.items():\n",
    "    df.loc[df['Entity'] == entity, ['Country', 'Continent']] = [country, continent]\n",
    "\n",
    "df[df['Entity'].isin(batch_a_mapping.keys())][['Entity', 'Country', 'Continent']].head(20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ee5368",
   "metadata": {},
   "source": [
    "## Batch B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "272bedf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Entity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Continent",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "c8bfac09-28f6-4f75-b15c-4b1646e73b70",
       "rows": [
        [
         "90",
         "Drupal",
         "United States",
         "North America"
        ],
        [
         "91",
         "DSW Inc.",
         "United States",
         "North America"
        ],
        [
         "92",
         "Dubsmash",
         "United States",
         "North America"
        ],
        [
         "93",
         "Dun & Bradstreet",
         "United States",
         "North America"
        ],
        [
         "94",
         "EasyJet",
         "United Kingdom",
         "Europe"
        ],
        [
         "95",
         "eBay",
         "United States",
         "North America"
        ],
        [
         "96",
         "Earl Enterprises(Buca di Beppo, Earl of Sandwich, Planet Hollywood,Chicken Guy, Mixology, Tequila Taqueria)",
         "United States",
         "North America"
        ],
        [
         "97",
         "Educational Credit Management Corporation",
         "United States",
         "North America"
        ],
        [
         "98",
         "Eisenhower Medical Center",
         "United States",
         "North America"
        ],
        [
         "99",
         "ElasticSearch",
         "United States",
         "North America"
        ],
        [
         "100",
         "Embassy Cables",
         "Multiple Countries",
         "Global"
        ],
        [
         "101",
         "Emergency Healthcare Physicians, Ltd.",
         "United States",
         "North America"
        ],
        [
         "102",
         "Emory Healthcare",
         "United States",
         "North America"
        ],
        [
         "103",
         "Equifax",
         "United States",
         "North America"
        ],
        [
         "104",
         "European Central Bank",
         "Germany",
         "Europe"
        ],
        [
         "105",
         "Evernote",
         "United States",
         "North America"
        ],
        [
         "106",
         "Exactis",
         "United States",
         "North America"
        ],
        [
         "107",
         "Excellus BlueCross BlueShield",
         "United States",
         "North America"
        ],
        [
         "108",
         "Experian - T-Mobile US",
         "United States",
         "North America"
        ],
        [
         "109",
         "EyeWire",
         "United States",
         "North America"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Drupal</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>DSW Inc.</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Dubsmash</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Dun &amp; Bradstreet</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>EasyJet</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>eBay</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Earl Enterprises(Buca di Beppo, Earl of Sandwi...</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Educational Credit Management Corporation</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Eisenhower Medical Center</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ElasticSearch</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Embassy Cables</td>\n",
       "      <td>Multiple Countries</td>\n",
       "      <td>Global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Emergency Healthcare Physicians, Ltd.</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Emory Healthcare</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Equifax</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>European Central Bank</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Evernote</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Exactis</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Excellus BlueCross BlueShield</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Experian - T-Mobile US</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>EyeWire</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Entity             Country  \\\n",
       "90                                              Drupal       United States   \n",
       "91                                            DSW Inc.       United States   \n",
       "92                                            Dubsmash       United States   \n",
       "93                                    Dun & Bradstreet       United States   \n",
       "94                                             EasyJet      United Kingdom   \n",
       "95                                                eBay       United States   \n",
       "96   Earl Enterprises(Buca di Beppo, Earl of Sandwi...       United States   \n",
       "97           Educational Credit Management Corporation       United States   \n",
       "98                           Eisenhower Medical Center       United States   \n",
       "99                                       ElasticSearch       United States   \n",
       "100                                     Embassy Cables  Multiple Countries   \n",
       "101              Emergency Healthcare Physicians, Ltd.       United States   \n",
       "102                                   Emory Healthcare       United States   \n",
       "103                                            Equifax       United States   \n",
       "104                              European Central Bank             Germany   \n",
       "105                                           Evernote       United States   \n",
       "106                                            Exactis       United States   \n",
       "107                      Excellus BlueCross BlueShield       United States   \n",
       "108                             Experian - T-Mobile US       United States   \n",
       "109                                            EyeWire       United States   \n",
       "\n",
       "         Continent  \n",
       "90   North America  \n",
       "91   North America  \n",
       "92   North America  \n",
       "93   North America  \n",
       "94          Europe  \n",
       "95   North America  \n",
       "96   North America  \n",
       "97   North America  \n",
       "98   North America  \n",
       "99   North America  \n",
       "100         Global  \n",
       "101  North America  \n",
       "102  North America  \n",
       "103  North America  \n",
       "104         Europe  \n",
       "105  North America  \n",
       "106  North America  \n",
       "107  North America  \n",
       "108  North America  \n",
       "109  North America  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_b_mapping = {\n",
    "    \"Drupal\": (\"United States\", \"North America\"),\n",
    "    \"DSW Inc.\": (\"United States\", \"North America\"),\n",
    "    \"Dubsmash\": (\"United States\", \"North America\"),\n",
    "    \"Dun & Bradstreet\": (\"United States\", \"North America\"),\n",
    "    \"EasyJet\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"eBay\": (\"United States\", \"North America\"),\n",
    "    \"Earl Enterprises(Buca di Beppo, Earl of Sandwich, Planet Hollywood,Chicken Guy, Mixology, Tequila Taqueria)\": (\"United States\", \"North America\"),\n",
    "    \"Educational Credit Management Corporation\": (\"United States\", \"North America\"),\n",
    "    \"Eisenhower Medical Center\": (\"United States\", \"North America\"),\n",
    "    \"ElasticSearch\": (\"United States\", \"North America\"),\n",
    "    \"Embassy Cables\": (\"Multiple Countries\", \"Global\"),\n",
    "    \"Emergency Healthcare Physicians, Ltd.\": (\"United States\", \"North America\"),\n",
    "    \"Emory Healthcare\": (\"United States\", \"North America\"),\n",
    "    \"Equifax\": (\"United States\", \"North America\"),\n",
    "    \"European Central Bank\": (\"Germany\", \"Europe\"),\n",
    "    \"Evernote\": (\"United States\", \"North America\"),\n",
    "    \"Exactis\": (\"United States\", \"North America\"),\n",
    "    \"Excellus BlueCross BlueShield\": (\"United States\", \"North America\"),\n",
    "    \"Experian - T-Mobile US\": (\"United States\", \"North America\"),\n",
    "    \"EyeWire\": (\"United States\", \"North America\"),\n",
    "    \"Facebook\": (\"United States\", \"North America\"),\n",
    "    \"Fast Retailing\": (\"Japan\", \"Asia\"),\n",
    "    \"Federal Reserve Bank of Cleveland\": (\"United States\", \"North America\"),\n",
    "    \"Fidelity National Information Services\": (\"United States\", \"North America\"),\n",
    "    \"First American Corporation\": (\"United States\", \"North America\"),\n",
    "    \"FireEye\": (\"United States\", \"North America\"),\n",
    "    \"Florida Department of Juvenile Justice\": (\"United States\", \"North America\"),\n",
    "    \"Friend Finder Networks\": (\"United States\", \"North America\"),\n",
    "    \"Funimation\": (\"United States\", \"North America\"),\n",
    "    \"Formspring\": (\"United States\", \"North America\"),\n",
    "    \"Unknown\": (\"Unknown\", \"Unknown\"),\n",
    "    \"Gamigo\": (\"Germany\", \"Europe\"),\n",
    "    \"Gap Inc.\": (\"United States\", \"North America\"),\n",
    "    \"Gawker\": (\"United States\", \"North America\"),\n",
    "    \"Global Payments\": (\"United States\", \"North America\"),\n",
    "    \"Gmail\": (\"United States\", \"North America\"),\n",
    "    \"Google Plus\": (\"United States\", \"North America\"),\n",
    "    \"Greek government\": (\"Greece\", \"Europe\"),\n",
    "    \"Grozio Chirurgija\": (\"Lithuania\", \"Europe\"),\n",
    "    \"GS Caltex\": (\"South Korea\", \"Asia\"),\n",
    "    \"Gyft\": (\"United States\", \"North America\"),\n",
    "    \"Hannaford Brothers Supermarket Chain\": (\"United States\", \"North America\"),\n",
    "    \"HauteLook\": (\"United States\", \"North America\"),\n",
    "    \"Health Net\": (\"United States\", \"North America\"),\n",
    "    \"Health Net — IBM\": (\"United States\", \"North America\"),\n",
    "    \"Health Sciences Authority (Singapore)\": (\"Singapore\", \"Asia\"),\n",
    "    \"Health Service Executive\": (\"Ireland\", \"Europe\"),\n",
    "    \"Heartland\": (\"United States\", \"North America\"),\n",
    "    \"Heathrow Airport\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"Hewlett Packard\": (\"United States\", \"North America\"),\n",
    "    \"Hilton Hotels\": (\"United States\", \"North America\"),\n",
    "    \"Home Depot\": (\"United States\", \"North America\"),\n",
    "    \"Honda Canada\": (\"Canada\", \"North America\"),\n",
    "    \"Hyatt Hotels\": (\"United States\", \"North America\"),\n",
    "    \"Iberdrola\": (\"Spain\", \"Europe\"),\n",
    "    \"Instagram\": (\"United States\", \"North America\"),\n",
    "    \"Internal Revenue Service\": (\"United States\", \"North America\"),\n",
    "    \"International Committee of the Red Cross\": (\"Switzerland\", \"Europe\"),\n",
    "    \"Inuvik hospital\": (\"Canada\", \"North America\"),\n",
    "    \"Iranian banks (three: Saderat, Eghtesad Novin, and Saman)\": (\"Iran\", \"Asia\"),\n",
    "    \"Japan Pension Service\": (\"Japan\", \"Asia\"),\n",
    "    \"Japanet Takata\": (\"Japan\", \"Asia\"),\n",
    "    \"Jefferson County, West Virginia\": (\"United States\", \"North America\"),\n",
    "    \"JP Morgan Chase\": (\"United States\", \"North America\"),\n",
    "    \"Justdial\": (\"India\", \"Asia\"),\n",
    "    \"KDDI\": (\"Japan\", \"Asia\"),\n",
    "    \"Kirkwood Community College\": (\"United States\", \"North America\"),\n",
    "    \"KM.RU\": (\"Russia\", \"Europe\"),\n",
    "    \"Koodo Mobile\": (\"Canada\", \"North America\"),\n",
    "    \"Korea Credit Bureau\": (\"South Korea\", \"Asia\"),\n",
    "    \"Kroll Background America\": (\"United States\", \"North America\"),\n",
    "    \"KT Corporation\": (\"South Korea\", \"Asia\"),\n",
    "    \"LexisNexis\": (\"United States\", \"North America\"),\n",
    "    \"Landry's, Inc.\": (\"United States\", \"North America\"),\n",
    "    \"Les Éditions Protégez-vous\": (\"Canada\", \"North America\"),\n",
    "    \"LifeLabs\": (\"Canada\", \"North America\"),\n",
    "    \"Lincoln Medical & Mental Health Center\": (\"United States\", \"North America\"),\n",
    "    \"LinkedIn, eHarmony, Last.fm\": (\"Multiple Countries\", \"Global\"),\n",
    "    \"Living Social\": (\"United States\", \"North America\"),\n",
    "    \"MacRumors.com\": (\"United States\", \"North America\"),\n",
    "    \"Mandarin Oriental Hotels\": (\"Hong Kong\", \"Asia\"),\n",
    "    \"Marriott International\": (\"United States\", \"North America\"),\n",
    "    \"Massachusetts Government\": (\"United States\", \"North America\")\n",
    "}\n",
    "\n",
    "for entity, (country, continent) in batch_b_mapping.items():\n",
    "    df.loc[df['Entity'] == entity, ['Country', 'Continent']] = [country, continent]\n",
    "\n",
    "df[df['Entity'].isin(batch_b_mapping.keys())][['Entity', 'Country', 'Continent']].head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd32f3a",
   "metadata": {},
   "source": [
    "## Batch C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00301a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Entity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Continent",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "47935195-ec92-4165-a81f-33aef0ed9bd3",
       "rows": [
        [
         "179",
         "Massive American business hack including 7-Eleven and Nasdaq",
         "Multiple Countries",
         "Global"
        ],
        [
         "180",
         "US Medicaid",
         "United States",
         "North America"
        ],
        [
         "181",
         "Medical Informatics Engineering",
         "United States",
         "North America"
        ],
        [
         "182",
         "Memorial Healthcare System",
         "United States",
         "North America"
        ],
        [
         "183",
         "Michaels",
         "United States",
         "North America"
        ],
        [
         "184",
         "Microsoft",
         "United States",
         "North America"
        ],
        [
         "185",
         "Microsoft Exchange servers",
         "United States",
         "North America"
        ],
        [
         "186",
         "Militarysingles.com",
         "United States",
         "North America"
        ],
        [
         "187",
         "Ministry of Education (Chile)",
         "Chile",
         "South America"
        ],
        [
         "188",
         "Ministry of Health (Singapore)",
         "Singapore",
         "Asia"
        ],
        [
         "189",
         "Mitsubishi Tokyo UFJ Bank",
         "Japan",
         "Asia"
        ],
        [
         "190",
         "MongoDB",
         "United States",
         "North America"
        ],
        [
         "191",
         "MongoDB",
         "United States",
         "North America"
        ],
        [
         "193",
         "Monster.com",
         "United States",
         "North America"
        ],
        [
         "194",
         "Morgan Stanley Smith Barney",
         "United States",
         "North America"
        ],
        [
         "195",
         "Morinaga Confectionery",
         "Japan",
         "Asia"
        ],
        [
         "196",
         "Mozilla",
         "United States",
         "North America"
        ],
        [
         "197",
         "MyHeritage",
         "Israel",
         "Asia"
        ],
        [
         "198",
         "NASDAQ",
         "United States",
         "North America"
        ],
        [
         "199",
         "Natural Grocers",
         "United States",
         "North America"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Massive American business hack including 7-Ele...</td>\n",
       "      <td>Multiple Countries</td>\n",
       "      <td>Global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>US Medicaid</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Medical Informatics Engineering</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Memorial Healthcare System</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Michaels</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Microsoft Exchange servers</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Militarysingles.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Ministry of Education (Chile)</td>\n",
       "      <td>Chile</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Ministry of Health (Singapore)</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Mitsubishi Tokyo UFJ Bank</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>MongoDB</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>MongoDB</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Monster.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Morgan Stanley Smith Barney</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Morinaga Confectionery</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Mozilla</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>MyHeritage</td>\n",
       "      <td>Israel</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Natural Grocers</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Entity             Country  \\\n",
       "179  Massive American business hack including 7-Ele...  Multiple Countries   \n",
       "180                                        US Medicaid       United States   \n",
       "181                    Medical Informatics Engineering       United States   \n",
       "182                         Memorial Healthcare System       United States   \n",
       "183                                           Michaels       United States   \n",
       "184                                          Microsoft       United States   \n",
       "185                         Microsoft Exchange servers       United States   \n",
       "186                                Militarysingles.com       United States   \n",
       "187                      Ministry of Education (Chile)               Chile   \n",
       "188                     Ministry of Health (Singapore)           Singapore   \n",
       "189                          Mitsubishi Tokyo UFJ Bank               Japan   \n",
       "190                                            MongoDB       United States   \n",
       "191                                            MongoDB       United States   \n",
       "193                                        Monster.com       United States   \n",
       "194                        Morgan Stanley Smith Barney       United States   \n",
       "195                             Morinaga Confectionery               Japan   \n",
       "196                                            Mozilla       United States   \n",
       "197                                         MyHeritage              Israel   \n",
       "198                                             NASDAQ       United States   \n",
       "199                                    Natural Grocers       United States   \n",
       "\n",
       "         Continent  \n",
       "179         Global  \n",
       "180  North America  \n",
       "181  North America  \n",
       "182  North America  \n",
       "183  North America  \n",
       "184  North America  \n",
       "185  North America  \n",
       "186  North America  \n",
       "187  South America  \n",
       "188           Asia  \n",
       "189           Asia  \n",
       "190  North America  \n",
       "191  North America  \n",
       "193  North America  \n",
       "194  North America  \n",
       "195           Asia  \n",
       "196  North America  \n",
       "197           Asia  \n",
       "198  North America  \n",
       "199  North America  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_c_mapping = {\n",
    "    \"Massive American business hack including 7-Eleven and Nasdaq\": (\"Multiple Countries\", \"Global\"),\n",
    "    \"US Medicaid\": (\"United States\", \"North America\"),\n",
    "    \"Medical Informatics Engineering\": (\"United States\", \"North America\"),\n",
    "    \"Memorial Healthcare System\": (\"United States\", \"North America\"),\n",
    "    \"Michaels\": (\"United States\", \"North America\"),\n",
    "    \"Microsoft\": (\"United States\", \"North America\"),\n",
    "    \"Microsoft Exchange servers\": (\"United States\", \"North America\"),\n",
    "    \"Militarysingles.com\": (\"United States\", \"North America\"),\n",
    "    \"Ministry of Education (Chile)\": (\"Chile\", \"South America\"),\n",
    "    \"Ministry of Health (Singapore)\": (\"Singapore\", \"Asia\"),\n",
    "    \"Mitsubishi Tokyo UFJ Bank\": (\"Japan\", \"Asia\"),\n",
    "    \"MongoDB\": (\"United States\", \"North America\"),\n",
    "    \"Monster.com\": (\"United States\", \"North America\"),\n",
    "    \"Morgan Stanley Smith Barney\": (\"United States\", \"North America\"),\n",
    "    \"Morinaga Confectionery\": (\"Japan\", \"Asia\"),\n",
    "    \"Mozilla\": (\"United States\", \"North America\"),\n",
    "    \"MyHeritage\": (\"Israel\", \"Asia\"),\n",
    "    \"NASDAQ\": (\"United States\", \"North America\"),\n",
    "    \"Natural Grocers\": (\"United States\", \"North America\"),\n",
    "    \"NEC Networks, LLC\": (\"United States\", \"North America\"),\n",
    "    \"Neiman Marcus\": (\"United States\", \"North America\"),\n",
    "    \"Nemours Foundation\": (\"United States\", \"North America\"),\n",
    "    \"Network Solutions\": (\"United States\", \"North America\"),\n",
    "    \"New York City Health & Hospitals Corp.\": (\"United States\", \"North America\"),\n",
    "    \"New York State Electric & Gas\": (\"United States\", \"North America\"),\n",
    "    \"New York Taxis\": (\"United States\", \"North America\"),\n",
    "    \"Nexon Korea Corp\": (\"South Korea\", \"Asia\"),\n",
    "    \"NHS\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"Nintendo (Club Nintendo)\": (\"Japan\", \"Asia\"),\n",
    "    \"Nintendo (Nintendo Account)\": (\"Japan\", \"Asia\"),\n",
    "    \"Nippon Television\": (\"Japan\", \"Asia\"),\n",
    "    \"Nival Networks\": (\"Russia\", \"Europe\"),\n",
    "    \"Norwegian Tax Administration\": (\"Norway\", \"Europe\"),\n",
    "    \"Now:Pensions\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"Ofcom\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"US Office of Personnel Management\": (\"United States\", \"North America\"),\n",
    "    \"Office of the Texas Attorney General\": (\"United States\", \"North America\"),\n",
    "    \"Ohio State University\": (\"United States\", \"North America\"),\n",
    "    \"Orbitz\": (\"United States\", \"North America\"),\n",
    "    \"Oregon Department of Transportation\": (\"United States\", \"North America\"),\n",
    "    \"OVH\": (\"France\", \"Europe\"),\n",
    "    \"Patreon\": (\"United States\", \"North America\"),\n",
    "    \"PayPay\": (\"Japan\", \"Asia\"),\n",
    "    \"Popsugar\": (\"United States\", \"North America\"),\n",
    "    \"Premera\": (\"United States\", \"North America\"),\n",
    "    \"Puerto Rico Department of Health\": (\"United States\", \"North America\"),\n",
    "    \"Quest Diagnostics\": (\"United States\", \"North America\"),\n",
    "    \"Quora\": (\"United States\", \"North America\"),\n",
    "    \"Rakuten\": (\"Japan\", \"Asia\"),\n",
    "    \"Rambler.ru\": (\"Russia\", \"Europe\"),\n",
    "    \"RBS Worldpay\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"Reddit\": (\"United States\", \"North America\"),\n",
    "    \"Restaurant Depot\": (\"United States\", \"North America\"),\n",
    "    \"RockYou!\": (\"United States\", \"North America\"),\n",
    "    \"Rosen Hotels\": (\"United States\", \"North America\"),\n",
    "    \"Sakai City, Japan\": (\"Japan\", \"Asia\"),\n",
    "    \"San Francisco Public Utilities Commission\": (\"United States\", \"North America\"),\n",
    "    \"Scottrade\": (\"United States\", \"North America\"),\n",
    "    \"Scribd\": (\"United States\", \"North America\"),\n",
    "    \"Seacoast Radiology, PA\": (\"United States\", \"North America\"),\n",
    "    \"Sega\": (\"Japan\", \"Asia\"),\n",
    "    \"Service Personnel and Veterans Agency (UK)\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"ShopBack\": (\"Singapore\", \"Asia\"),\n",
    "    \"SingHealth\": (\"Singapore\", \"Asia\"),\n",
    "    \"Slack\": (\"United States\", \"North America\"),\n",
    "    \"SlickWraps\": (\"United States\", \"North America\"),\n",
    "    \"SnapChat\": (\"United States\", \"North America\"),\n",
    "    \"SolarWinds\": (\"United States\", \"North America\"),\n",
    "    \"Sony Online Entertainment\": (\"United States\", \"North America\"),\n",
    "    \"Sony Pictures\": (\"United States\", \"North America\"),\n",
    "    \"Sony PlayStation Network\": (\"Japan\", \"Asia\"),\n",
    "    \"South Africa police\": (\"South Africa\", \"Africa\"),\n",
    "    \"South Carolina Government\": (\"United States\", \"North America\"),\n",
    "    \"South Shore Hospital, Massachusetts\": (\"United States\", \"North America\"),\n",
    "    \"Southern California Medical-Legal Consultants\": (\"United States\", \"North America\"),\n",
    "    \"Spartanburg Regional Healthcare System\": (\"United States\", \"North America\"),\n",
    "    \"Stanford University\": (\"United States\", \"North America\"),\n",
    "    \"Starbucks\": (\"United States\", \"North America\"),\n",
    "    \"Starwoodincluding Westin Hotels & Resorts and Sheraton Hotels and Resorts\": (\"United States\", \"North America\"),\n",
    "    \"State of Texas\": (\"United States\", \"North America\"),\n",
    "    \"Steam\": (\"United States\", \"North America\"),\n",
    "    \"StockX\": (\"United States\", \"North America\"),\n",
    "    \"Stratfor\": (\"United States\", \"North America\"),\n",
    "    \"Supervalu\": (\"United States\", \"North America\"),\n",
    "    \"Sutter Medical Center\": (\"United States\", \"North America\"),\n",
    "    \"Syrian government (Syria Files)\": (\"Syria\", \"Asia\")\n",
    "}\n",
    "\n",
    "for entity, (country, continent) in batch_c_mapping.items():\n",
    "    df.loc[df['Entity'] == entity, ['Country', 'Continent']] = [country, continent]\n",
    "\n",
    "df[df['Entity'].isin(batch_c_mapping.keys())][['Entity', 'Country', 'Continent']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c50669",
   "metadata": {},
   "source": [
    "## Batch D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ada5a225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Entity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Continent",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "cad95632-8a76-4399-aa01-b22e88f69ef3",
       "rows": [
        [
         "268",
         "Taobao",
         "China",
         "Asia"
        ],
        [
         "269",
         "Taringa!",
         "Argentina",
         "South America"
        ],
        [
         "270",
         "Target Corporation",
         "United States",
         "North America"
        ],
        [
         "271",
         "TaxSlayer.com",
         "United States",
         "North America"
        ],
        [
         "273",
         "TD Bank",
         "United States",
         "North America"
        ],
        [
         "274",
         "TerraCom & YourTel",
         "United States",
         "North America"
        ],
        [
         "275",
         "Tetrad",
         "United States",
         "North America"
        ],
        [
         "276",
         "Texas Lottery",
         "United States",
         "North America"
        ],
        [
         "277",
         "Ticketfly (subsidiary of Eventbrite)",
         "United States",
         "North America"
        ],
        [
         "278",
         "Tianya Club",
         "China",
         "Asia"
        ],
        [
         "279",
         "TikTok",
         "China",
         "Asia"
        ],
        [
         "280",
         "TK / TJ Maxx",
         "United States",
         "North America"
        ],
        [
         "281",
         "T-Mobile, Deutsche Telekom",
         "Germany",
         "Europe"
        ],
        [
         "282",
         "T-Mobile",
         "United States",
         "North America"
        ],
        [
         "283",
         "Tricare",
         "United States",
         "North America"
        ],
        [
         "284",
         "Triple-S Salud, Inc.",
         "United States",
         "North America"
        ],
        [
         "285",
         "Truecaller",
         "Sweden",
         "Europe"
        ],
        [
         "286",
         "Trump Hotels",
         "United States",
         "North America"
        ],
        [
         "287",
         "Tumblr",
         "United States",
         "North America"
        ],
        [
         "288",
         "Twitch",
         "United States",
         "North America"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Taobao</td>\n",
       "      <td>China</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Taringa!</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Target Corporation</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>TaxSlayer.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>TD Bank</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>TerraCom &amp; YourTel</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Tetrad</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Texas Lottery</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Ticketfly (subsidiary of Eventbrite)</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Tianya Club</td>\n",
       "      <td>China</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>TikTok</td>\n",
       "      <td>China</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>TK / TJ Maxx</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>T-Mobile, Deutsche Telekom</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>T-Mobile</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Tricare</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Triple-S Salud, Inc.</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Truecaller</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Trump Hotels</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Tumblr</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Twitch</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Entity        Country      Continent\n",
       "268                                Taobao          China           Asia\n",
       "269                              Taringa!      Argentina  South America\n",
       "270                    Target Corporation  United States  North America\n",
       "271                         TaxSlayer.com  United States  North America\n",
       "273                               TD Bank  United States  North America\n",
       "274                    TerraCom & YourTel  United States  North America\n",
       "275                                Tetrad  United States  North America\n",
       "276                         Texas Lottery  United States  North America\n",
       "277  Ticketfly (subsidiary of Eventbrite)  United States  North America\n",
       "278                           Tianya Club          China           Asia\n",
       "279                                TikTok          China           Asia\n",
       "280                          TK / TJ Maxx  United States  North America\n",
       "281            T-Mobile, Deutsche Telekom        Germany         Europe\n",
       "282                              T-Mobile  United States  North America\n",
       "283                               Tricare  United States  North America\n",
       "284                  Triple-S Salud, Inc.  United States  North America\n",
       "285                            Truecaller         Sweden         Europe\n",
       "286                          Trump Hotels  United States  North America\n",
       "287                                Tumblr  United States  North America\n",
       "288                                Twitch  United States  North America"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_d_mapping = {\n",
    "    \"Taobao\": (\"China\", \"Asia\"),\n",
    "    \"Taringa!\": (\"Argentina\", \"South America\"),\n",
    "    \"Target Corporation\": (\"United States\", \"North America\"),\n",
    "    \"TaxSlayer.com\": (\"United States\", \"North America\"),\n",
    "    \"TD Bank\": (\"United States\", \"North America\"),\n",
    "    \"TerraCom & YourTel\": (\"United States\", \"North America\"),\n",
    "    \"Tetrad\": (\"United States\", \"North America\"),\n",
    "    \"Texas Lottery\": (\"United States\", \"North America\"),\n",
    "    \"Ticketfly (subsidiary of Eventbrite)\": (\"United States\", \"North America\"),\n",
    "    \"Tianya Club\": (\"China\", \"Asia\"),\n",
    "    \"TikTok\": (\"China\", \"Asia\"),\n",
    "    \"TK / TJ Maxx\": (\"United States\", \"North America\"),\n",
    "    \"T-Mobile, Deutsche Telekom\": (\"Germany\", \"Europe\"),\n",
    "    \"T-Mobile\": (\"United States\", \"North America\"),\n",
    "    \"Tricare\": (\"United States\", \"North America\"),\n",
    "    \"Triple-S Salud, Inc.\": (\"United States\", \"North America\"),\n",
    "    \"Truecaller\": (\"Sweden\", \"Europe\"),\n",
    "    \"Trump Hotels\": (\"United States\", \"North America\"),\n",
    "    \"Tumblr\": (\"United States\", \"North America\"),\n",
    "    \"Twitch\": (\"United States\", \"North America\"),\n",
    "    \"Twitter\": (\"United States\", \"North America\"),\n",
    "    \"Typeform\": (\"Spain\", \"Europe\"),\n",
    "    \"Uber\": (\"United States\", \"North America\"),\n",
    "    \"Ubisoft\": (\"France\", \"Europe\"),\n",
    "    \"Ubuntu\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"UCLA Medical Center, Santa Monica\": (\"United States\", \"North America\"),\n",
    "    \"UK Home Office\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"UK Ministry of Defence\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"UK Revenue & Customs\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"Universiti Teknologi MARA\": (\"Malaysia\", \"Asia\"),\n",
    "    \"Under Armour\": (\"United States\", \"North America\"),\n",
    "    \"University of California, Berkeley\": (\"United States\", \"North America\"),\n",
    "    \"University of Maryland, College Park\": (\"United States\", \"North America\"),\n",
    "    \"University of Central Florida\": (\"United States\", \"North America\"),\n",
    "    \"University of Miami\": (\"United States\", \"North America\"),\n",
    "    \"University of Utah Hospital & Clinics\": (\"United States\", \"North America\"),\n",
    "    \"University of Wisconsin–Milwaukee\": (\"United States\", \"North America\"),\n",
    "    \"United States Postal Service\": (\"United States\", \"North America\"),\n",
    "    \"UPS\": (\"United States\", \"North America\"),\n",
    "    \"U.S. Army\": (\"United States\", \"North America\"),\n",
    "    \"U.S. Army(classified Iraq War documents)\": (\"United States\", \"North America\"),\n",
    "    \"U.S. Department of Defense\": (\"United States\", \"North America\"),\n",
    "    \"U.S. Department of Veteran Affairs\": (\"United States\", \"North America\"),\n",
    "    \"U.S. federal government (2020 United States federal government data breach)\": (\"United States\", \"North America\"),\n",
    "    \"U.S. law enforcement (70 different agencies)\": (\"Multiple Countries\", \"Global\"),\n",
    "    \"National Archives and Records Administration (U.S. military veterans records)\": (\"United States\", \"North America\"),\n",
    "    \"U.S. government (United States diplomatic cables leak)\": (\"United States\", \"North America\"),\n",
    "    \"National Guard of the United States\": (\"United States\", \"North America\"),\n",
    "    \"Vastaamo\": (\"Finland\", \"Europe\"),\n",
    "    \"Verizon Communications\": (\"United States\", \"North America\"),\n",
    "    \"View Media\": (\"United States\", \"North America\"),\n",
    "    \"Virgin Media\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"Virginia Department of Health\": (\"United States\", \"North America\"),\n",
    "    \"Virginia Prescription Monitoring Program\": (\"United States\", \"North America\"),\n",
    "    \"Vodafone\": (\"United Kingdom\", \"Europe\"),\n",
    "    \"VTech\": (\"Hong Kong\", \"Asia\"),\n",
    "    \"Walmart\": (\"United States\", \"North America\"),\n",
    "    \"Washington Post\": (\"United States\", \"North America\"),\n",
    "    \"Washington State court system\": (\"United States\", \"North America\"),\n",
    "    \"Wattpad\": (\"Canada\", \"North America\"),\n",
    "    \"Wawa (company)\": (\"United States\", \"North America\"),\n",
    "    \"Weebly\": (\"United States\", \"North America\"),\n",
    "    \"Wendy's\": (\"United States\", \"North America\"),\n",
    "    \"Westpac\": (\"Australia\", \"Oceania\"),\n",
    "    \"Woodruff Arts Center\": (\"United States\", \"North America\"),\n",
    "    \"Writerspace.com\": (\"United States\", \"North America\"),\n",
    "    \"Xat.com\": (\"United States\", \"North America\"),\n",
    "    \"Yahoo\": (\"United States\", \"North America\"),\n",
    "    \"Yahoo Japan\": (\"Japan\", \"Asia\"),\n",
    "    \"Yahoo! Voices\": (\"United States\", \"North America\"),\n",
    "    \"Yale University\": (\"United States\", \"North America\"),\n",
    "    \"YouTube\": (\"United States\", \"North America\"),\n",
    "    \"Zappos\": (\"United States\", \"North America\"),\n",
    "    \"Zynga\": (\"United States\", \"North America\"),\n",
    "    \"Unknown agency(believed to be tied to United States Census Bureau)\": (\"United States\", \"North America\"),\n",
    "    \"National Health Information Center (NCZI) of Slovakia\": (\"Slovakia\", \"Europe\"),\n",
    "    \"50 companies and government institutions\": (\"Multiple Countries\", \"Global\"),\n",
    "    \"IKEA\": (\"Netherlands\", \"Europe\")\n",
    "}\n",
    "\n",
    "for entity, (country, continent) in batch_d_mapping.items():\n",
    "    df.loc[df['Entity'] == entity, ['Country', 'Continent']] = [country, continent]\n",
    "\n",
    "df[df['Entity'].isin(batch_d_mapping.keys())][['Entity', 'Country', 'Continent']].head(20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
